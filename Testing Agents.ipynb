{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c4b33e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "from matplotlib import pyplot as plt\n",
    "from pettingzoo.atari import space_invaders_v2\n",
    "from pettingzoo.sisl import pursuit_v4\n",
    "import gym\n",
    "from gym.wrappers import RecordVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df3f356",
   "metadata": {},
   "source": [
    "# Testing agent trained for parameter sharing with free evaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9b09f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_states, n_actions):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(n_states, 64)\n",
    "        self.layer2 = nn.Linear(64, 64)\n",
    "        self.out = nn.Linear(64,n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "072b2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = pursuit_v4.env(max_cycles=500, x_size=16, y_size=16, shared_reward=True, n_evaders=25,\n",
    "n_pursuers=6,obs_range=7, n_catch=2, freeze_evaders=False, tag_reward=0.01,\n",
    "catch_reward=5.0, urgency_reward=0, surround=True, constraint_window=1.0, render_mode = 'rgb_array')\n",
    "\n",
    "#env = RecordVideo(env, \"DQN_combined_500.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1d985bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQN(3*7*7, 5)\n",
    "policy_net.load_state_dict(torch.load(\"DQN_combined_500\"))\n",
    "policy_net.eval()\n",
    "\n",
    "env.reset()\n",
    "time = 0\n",
    "frames = []\n",
    "for agent in env.agent_iter():\n",
    "    observation, reward, termination, truncation, info = env.last()\n",
    "    observation = torch.tensor(observation).to(torch.float)\n",
    "    observation = (torch.flatten(observation)).unsqueeze(0)\n",
    "    if termination or truncation:\n",
    "        a = None\n",
    "    else:\n",
    "        a = (policy_net(observation).max(1)[1]).item()\n",
    "    env.step(a)\n",
    "    frames.append(env.render())\n",
    "    time+=1\n",
    "#     if time>=3000:\n",
    "#         break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "555593f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "08862e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [Image.fromarray(frame) for frame in frames]\n",
    "frame_one = frames[0]\n",
    "frame_one.save(\"DQN_combined_500.gif\", format=\"GIF\", append_images=frames,\n",
    "               save_all=True, duration=0.5, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc88e5",
   "metadata": {},
   "source": [
    "# Testing agent trained for parameter sharing with frozen evaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f6078462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "env = pursuit_v4.env(max_cycles=500, x_size=16, y_size=16, shared_reward=True, n_evaders=25,\n",
    "n_pursuers=6,obs_range=7, n_catch=2, freeze_evaders=True, tag_reward=0.01,\n",
    "catch_reward=5.0, urgency_reward=0, surround=True, constraint_window=1.0, render_mode = 'rgb_array')\n",
    "\n",
    "#env = RecordVideo(env, \"DQN_combined_500.mp4\")\n",
    "\n",
    "policy_net = DQN(3*7*7, 5)\n",
    "policy_net.load_state_dict(torch.load(\"DQN_combined_500_frozen\"))\n",
    "policy_net.eval()\n",
    "\n",
    "env.reset()\n",
    "time = 0\n",
    "frames = []\n",
    "for agent in env.agent_iter():\n",
    "    observation, reward, termination, truncation, info = env.last()\n",
    "    observation = torch.tensor(observation).to(torch.float)\n",
    "    observation = (torch.flatten(observation)).unsqueeze(0)\n",
    "    if termination or truncation:\n",
    "        a = None\n",
    "    else:\n",
    "        a = (policy_net(observation).max(1)[1]).item()\n",
    "    env.step(a)\n",
    "    frames.append(env.render())\n",
    "    time+=1\n",
    "#     if time>=3000:\n",
    "#         break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aa515a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [Image.fromarray(frame) for frame in frames]\n",
    "frame_one = frames[0]\n",
    "frame_one.save(\"DQN_combined_500_frozen.gif\", format=\"GIF\", append_images=frames,\n",
    "               save_all=True, duration=0.5, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568d73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7166f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e06b32c",
   "metadata": {},
   "source": [
    "# Testing agent trained for separate networks with free evaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "64baf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_states, n_actions):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(n_states, 128)\n",
    "        self.layer2 = nn.Linear(128,64)\n",
    "        self.layer3 = nn.Linear(64, 64)\n",
    "        self.out = nn.Linear(64,n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "98e7819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = pursuit_v4.env(max_cycles=500, x_size=16, y_size=16, shared_reward=True, n_evaders=25,\n",
    "n_pursuers=6,obs_range=7, n_catch=2, freeze_evaders=False, tag_reward=0.01,\n",
    "catch_reward=5.0, urgency_reward=0, surround=True, constraint_window=1.0, render_mode = 'rgb_array')\n",
    "\n",
    "policy_net = [DQN(3*7*7, 5)  for _ in range(6)]\n",
    "for i in range(6):\n",
    "    policy_net[i].load_state_dict(torch.load(\"DQN_separate\"+str(i)))\n",
    "    policy_net[i].eval()\n",
    "\n",
    "env.reset()\n",
    "time = 0\n",
    "frames = []\n",
    "for agent in env.agent_iter():\n",
    "    observation, reward, termination, truncation, info = env.last()\n",
    "    observation = torch.tensor(observation).to(torch.float)\n",
    "    observation = (torch.flatten(observation)).unsqueeze(0)\n",
    "    if termination or truncation:\n",
    "        a = None\n",
    "    else:\n",
    "        a = (policy_net[int(str(agent)[-1])](observation).max(1)[1]).item()\n",
    "    env.step(a)\n",
    "    frames.append(env.render())\n",
    "    time+=1\n",
    "#     if time>=3000:\n",
    "#         break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6474d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [Image.fromarray(frame) for frame in frames]\n",
    "frame_one = frames[0]\n",
    "frame_one.save(\"DQN_separate.gif\", format=\"GIF\", append_images=frames,\n",
    "               save_all=True, duration=0.5, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0d689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
